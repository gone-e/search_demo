import sys
sys.path.append(".")
import copy
import streamlit as st
import pandas as pd
from services import SERVICE_TO_ES
from ranking.commerce import *
# import demo.commerce.utils as card_utils
import demo.commerce.constants as constants
import demo.commerce.view as commerce_view
from demo.utils import (
    get_docs, 
    get_id2rank,
    get_rank_changes,
    get_analyze_result, 
    get_service_doc_url, 
    timediff
)
from demo.ohs_image import get_image_url
import demo.visualize as visualize
from myelasticsearch.explainer import ESExplainParser
import requests



# FIXME
SERVICE = "commerce"
TOBE_SERVICE = "commerce_dev"
DATA_CREATED_AT = "20220509"
ES = SERVICE_TO_ES[SERVICE]
ES_DEV = SERVICE_TO_ES[TOBE_SERVICE]

def load_random_query(data):
    df = pd.read_csv(data, keep_default_na=False)
    out = {}
    for idx, row in df.iterrows():
        out[row["search_keyword"]] = dict(row)
    return out


# NOTE: Í∞ÄÎä•Ìïú ÏÑúÎπÑÏä§ ÌéòÏù¥ÏßÄÏôÄ ÎπÑÏä∑Ìïú ÎäêÎÇåÏúºÎ°ú ÎÖ∏Ï∂úÌïòÏó¨ ÏÇ¨Ïö©ÏûêÏôÄ ÎπÑÏä∑Ìïú Í≤ΩÌóòÏùÑ ÎäêÎÇÑ Ïàò ÏûàÎèÑÎ°ù ÌïúÎã§.
def page():
    """ ÎÇ¥Ïô∏Î∂Ä Í≥µÏú† Ïö©ÎèÑÏùò ÌéòÏù¥ÏßÄ """
    st.title("üßΩ Ïä§ÌÜ†Ïñ¥ Í≤ÄÏÉâ(Commerce Search) Îç∞Î™®")

    option_debug = st.radio("Mode", ["Debug", "Normal"])

    querydata = load_random_query(f"../dataset/{SERVICE}/search_keywords.qc10.1w.1K.{DATA_CREATED_AT}.csv")

    query = st.selectbox(
        "Search",
        querydata.keys()
    )

    input_query = st.text_input(
        label="Search",
        placeholder="Í≤ÄÏÉâÏñ¥Î•º ÏûÖÎ†•Ìï¥Ï£ºÏÑ∏Ïöî."
    )

    content_only_negative = {
        "bool": {
            "must": [
                {
                    "multi_match": {
                        "fields": [
                            "content_keywords3"
                        ],
                        "operator": "and",
                        "query": input_query
                    }
                }
            ],
            "must_not": [
                {
                    "multi_match": {
                        "fields": [
                            "brand_name",
                            "brand_name.standard",
                            "brand_name.no_syn",
                            "name",
                            "name.standard",
                            "name.no_syn",
                            "search_keywords",
                            "search_keywords.standard",
                            "reinforcement",
                            "reinforcement.keyword",
                            "search_admin_categories",
                            "options"
                        ],
                        "operator": "and",
                        "query": input_query,
                        "type": "cross_fields"
                    }
                }
            ]
        }
    }

    content_only_negative2 = {
        "bool": {
            "must": [
                {
                    "multi_match": {
                        "fields": [
                            "content_keywords2"
                        ],
                        "operator": "and",
                        "query": input_query
                    }
                }
            ],
            "must_not": [
                {
                    "multi_match": {
                        "fields": [
                            "brand_name",
                            "brand_name.standard",
                            "brand_name.no_syn",
                            "name",
                            "name.standard",
                            "name.no_syn",
                            "search_keywords",
                            "search_keywords.standard",
                            "reinforcement",
                            "reinforcement.keyword",
                            "search_admin_categories",
                            "options"
                        ],
                        "operator": "and",
                        "query": input_query,
                        "type": "cross_fields"
                    }
                }
            ]
        }
    }

    if input_query.strip():
        query = input_query

    if query:
        st.subheader("Query Analyzer")

        dat = querydata.get(query)
        if dat is None:
            dat = {}

        st.subheader("[ÏÇ¨ÏßÑÌÉ≠ Í∏∞Ï§Ä] Î™®Î∞îÏùºÏï±: 4-6Í∞ú Í≤∞Í≥º / Ïõπ: 4-8Í∞ú Í≤∞Í≥º")
        st.subheader((
            f"Result"
            f" [QC={dat.get('qc')}, CC={dat.get('cc')}, CTR={dat.get('ctr', -1):.1f}"
            f", uQC(nSearchUsers)={dat.get('uqc')}, uCC(nClickUsers)={dat.get('ucc')}, uCTR={dat.get('uctr', -1):.1f}]"
        ))

        asis_res = ES.get_search_result(
            query, 
            # request_body=asis.generate(query, top_k=constants.TOP_K),
            # request_body=multimatch.generate(query, top_k=constants.TOP_K),
            # request_body=should_validate.generate(query, top_k=constants.TOP_K),
            explain=True, 
            top_k=constants.TOP_K,
            with_elapsed=True,
        )
        asis_docs = get_docs(asis_res)

        tobe_request_body = ES.get_service_request_body(query=query, page_size=constants.TOP_K, timeout_secs=20)
        tobe1_request_body = ES.get_service_request_body(query=query, page_size=constants.TOP_K, timeout_secs=20)

        # new_matching_query
        tobe_request_body['query']['boosting']['positive']['function_score']['query']['bool']['filter'][2]['bool'][
            'must'][0]['multi_match']['fields'].append("content_keywords3")
        tobe_request_body['query']['boosting']['positive']['function_score']['query']['bool']['filter'][1][
            'multi_match'][
            'fields'].append("content_keywords3")
       #tobe_request_body['query']['boosting']['negative_boost'] = 0.001

        tobe_request_body['query']['boosting']['negative']['bool']['should'].append(content_only_negative)

        tobe1_request_body['query']['boosting']['positive']['function_score']['query']['bool']['filter'][2]['bool'][
            'must'][0]['multi_match']['fields'].append("content_keywords")
        tobe1_request_body['query']['boosting']['positive']['function_score']['query']['bool']['filter'][1][
            'multi_match'][
            'fields'].append("content_keywords2")
        tobe1_request_body['query']['boosting']['negative']['bool']['should'].append(content_only_negative2)
        """
        if brand_query_res.get("brand_keyword"):
            new_rank_features = [
                {
                    "filter": {
                        "bool": {
                            "minimum_should_match": 1,
                            "should": [
                                {
                                    "multi_match": {
                                        "fields": [
                                            "brand_name",
                                            "processed_brand_name",
                                            "brand_name.standard",
                                            "brand_name.no_syn"
                                        ],
                                        "operator": "or",
                                        "query": brand_query_res.get("brand_keyword"),
                                        "type": "cross_fields"
                                    }
                                }
                            ]
                        }
                    },
                    "weight": 0.02068615
                }
            ]

            tobe_request_body['query']['boosting']['positive']['function_score']['functions'] = tobe_request_body['query']['boosting']['positive']['function_score']['functions'] + new_rank_features
        """
        #print(tobe_request_body)

        tobe_res = ES.get_search_result(
            # request_body=multimatch_to_match.generate(query, top_k=constants.TOP_K),
            # request_body=add_matching_similarity.generate(query, top_k=constants.TOP_K),
            # request_body=proximity.generate(query, top_k=constants.TOP_K),
            # request_body=normalize_bm25.generate(query, top_k=constants.TOP_K),
            # request_body=should_validate2.generate(query, top_k=constants.TOP_K),
            request_body=tobe_request_body,
            explain=True, 
            top_k=constants.TOP_K,
            with_elapsed=True,
        )

        tobe1_res = ES_DEV.get_search_result(
            # request_body=multimatch_to_match.generate(query, top_k=constants.TOP_K),
            # request_body=add_matching_similarity.generate(query, top_k=constants.TOP_K),
            # request_body=proximity.generate(query, top_k=constants.TOP_K),
            # request_body=normalize_bm25.generate(query, top_k=constants.TOP_K),
            # request_body=should_validate2.generate(query, top_k=constants.TOP_K),
            request_body=tobe1_request_body,
            explain=True,
            top_k=constants.TOP_K,
            with_elapsed=True,
        )

        tobe_docs = get_docs(tobe_res)
        tobe1_docs = get_docs(tobe1_res)

        # Í≤ÄÏÉâÏøºÎ¶¨Î¨∏
        col1, mid, col2 = st.columns([1, 1, 1])
        with col1:
            with st.expander("Request Body"):
                st.json(asis_res["requestBody"])

        with mid:
            with st.expander("Request Body"):
                st.json(tobe1_res["requestBody"])

        with col2:
            with st.expander("Request Body"):
                st.json(tobe_res["requestBody"])

        asis_id2rank = get_id2rank(asis_docs)
        tobe_id2rank = get_id2rank(tobe_docs)
        tobe1_id2rank = get_id2rank(tobe1_docs)

        if option_debug == "Debug":
            debug_cols = st.columns(3)
            # extra_cols[0].info(f"elapsed: {asis_elapsed}")
            # extra_cols[1].info(f"elapsed: {tobe_elapsed}")
            score_list = [doc["_score"] for doc in asis_docs]
            plot = visualize.draw_distribution(
                score_list, 
                x="Rank", 
                y="Score", 
                title="ASIS Score Distribution"
            )
            debug_cols[0].pyplot(plot)
            # debug_cols[0].write(f'Í≤ÄÏÉâÍ≤∞Í≥ºÏàò: {asis_res["result"]["hits"]["total"]["value"]}')

            score_list = [doc["_score"] for doc in tobe1_docs]
            plot = visualize.draw_distribution(
                score_list,
                x="Rank",
                y="Score",
                title="v1(only card) Score Distribution"
            )
            debug_cols[1].pyplot(plot)
            # debug_cols[1].write(f'Í≤ÄÏÉâÍ≤∞Í≥ºÏàò: {tobe_res["result"]["hits"]["total"]["value"]}')

            score_list = [doc["_score"] for doc in tobe_docs]
            plot = visualize.draw_distribution(
                score_list, 
                x="Rank", 
                y="Score", 
                title="v2(click, sim) Score Distribution"
            )
            debug_cols[2].pyplot(plot)
            # debug_cols[1].write(f'Í≤ÄÏÉâÍ≤∞Í≥ºÏàò: {tobe_res["result"]["hits"]["total"]["value"]}')

        num_cols = 8    # ÌôÄÏàòÎ°ú Î≥ÄÍ≤Ω: 5 ÎòêÎäî 7 Í∂åÏû•
        col_size_list = [1]*num_cols

        borders = []

        for idx, size in enumerate(col_size_list):
            if (idx+1) % 3 == 0:
                col_size_list[idx] = 0.2
                borders.append(idx)

        cols = st.columns(col_size_list)

        left_cols = cols[:borders[0]]
        mid_cols = cols[borders[0]+1:borders[1]]
        right_cols = cols[borders[1]+1:]

        for name, docs in [("asis", asis_docs), ("tobe", tobe_docs), ("tobe1", tobe1_docs)]:
            # select columns
            if name == "asis":
                this_cols = left_cols
            elif name == "tobe1":
                this_cols = mid_cols
            else:
                this_cols = right_cols

            if len(docs) == 0:
                col = this_cols[0]
                col.subheader("üôà Í≤ÄÏÉâÍ≤∞Í≥ºÏóÜÏùå!")
                continue

            for rank, doc in enumerate(docs):
                col = this_cols[rank % 2]

                if rank == constants.SHOW_K:
                    break

                with col:
                    doc_url, _ = ES.get_document(doc["_id"], only_return_url=True)

                    col.markdown((
                        f'{rank+1}.'
                        f'{get_rank_changes(asis_id2rank, tobe_id2rank, doc["_id"], constants.TOP_K)}'
                        f' **`Ï†êÏàò:{doc["_score"]}`**'
                        f' [{doc["_id"]}]({get_service_doc_url("Ïä§ÌÜ†Ïñ¥", doc["_id"])})'
                        f' [`doc`]({doc_url})'
                        # f' `{timediff(doc["created_at"][:10])}`'
                    ))
                    commerce_view.service_view(
                        col=col,
                        rank=rank+1, 
                        doc=doc, 
                        doc_url=doc_url, 
                        use_badges=False, 
                        debug=True if option_debug == "Debug" else False
                    )
