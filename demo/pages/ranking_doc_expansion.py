import sys
sys.path.append(".")
import copy
import streamlit as st
import pandas as pd
from services import SERVICE_TO_ES
from ranking.commerce import *
# import demo.commerce.utils as card_utils
import demo.commerce.constants as constants
import demo.commerce.view as commerce_view
from demo.utils import (
    get_docs, 
    get_id2rank,
    get_rank_changes,
    get_analyze_result, 
    get_service_doc_url, 
    timediff
)
from demo.ohs_image import get_image_url
import demo.visualize as visualize
from myelasticsearch.explainer import ESExplainParser
import requests



# FIXME
SERVICE = "commerce"
TOBE_SERVICE = "commerce_dev"
DATA_CREATED_AT = "20220509"
ES = SERVICE_TO_ES[SERVICE]
ES_DEV = SERVICE_TO_ES[TOBE_SERVICE]

def load_random_query(data):
    df = pd.read_csv(data, keep_default_na=False)
    out = {}
    for idx, row in df.iterrows():
        out[row["search_keyword"]] = dict(row)
    return out


# NOTE: ê°€ëŠ¥í•œ ì„œë¹„ìŠ¤ í˜ì´ì§€ì™€ ë¹„ìŠ·í•œ ëŠë‚Œìœ¼ë¡œ ë…¸ì¶œí•˜ì—¬ ì‚¬ìš©ìì™€ ë¹„ìŠ·í•œ ê²½í—˜ì„ ëŠë‚„ ìˆ˜ ìˆë„ë¡ í•œë‹¤.
def page():
    """ ë‚´ì™¸ë¶€ ê³µìœ  ìš©ë„ì˜ í˜ì´ì§€ """
    st.title("ğŸ§½ ìŠ¤í† ì–´ ê²€ìƒ‰(Commerce Search) ë°ëª¨")

    option_debug = st.radio("Mode", ["Debug", "Normal"])

    querydata = load_random_query(f"../dataset/{SERVICE}/search_keywords.qc10.1w.1K.{DATA_CREATED_AT}.csv")

    query = st.selectbox(
        "Search",
        querydata.keys()
    )

    input_query = st.text_input(
        label="Search",
        placeholder="ê²€ìƒ‰ì–´ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”."
    )

    content_only_negative = {
        "bool": {
            "must": [
                {
                    "multi_match": {
                        "fields": [
                            "content_keywords"
                        ],
                        "operator": "and",
                        "query": input_query
                    }
                }
            ],
            "must_not": [
                {
                    "multi_match": {
                        "fields": [
                            "brand_name",
                            "brand_name.standard",
                            "brand_name.no_syn",
                            "name",
                            "name.standard",
                            "name.no_syn",
                            "search_keywords",
                            "search_keywords.standard",
                            "reinforcement",
                            "reinforcement.keyword",
                            "search_admin_categories",
                            "options"
                        ],
                        "operator": "and",
                        "query": input_query,
                        "type": "cross_fields"
                    }
                }
            ]
        }
    }

    if input_query.strip():
        query = input_query

    if query:
        st.subheader("Query Analyzer")

        dat = querydata.get(query)
        if dat is None:
            dat = {}

        st.subheader("[ì‚¬ì§„íƒ­ ê¸°ì¤€] ëª¨ë°”ì¼ì•±: 4-6ê°œ ê²°ê³¼ / ì›¹: 4-8ê°œ ê²°ê³¼")
        st.subheader((
            f"Result"
            f" [QC={dat.get('qc')}, CC={dat.get('cc')}, CTR={dat.get('ctr', -1):.1f}"
            f", uQC(nSearchUsers)={dat.get('uqc')}, uCC(nClickUsers)={dat.get('ucc')}, uCTR={dat.get('uctr', -1):.1f}]"
        ))

        asis_res = ES.get_search_result(
            query, 
            # request_body=asis.generate(query, top_k=constants.TOP_K),
            # request_body=multimatch.generate(query, top_k=constants.TOP_K),
            # request_body=should_validate.generate(query, top_k=constants.TOP_K),
            explain=True, 
            top_k=constants.TOP_K,
            with_elapsed=True,
        )
        asis_docs = get_docs(asis_res)

        tobe_request_body = ES.get_service_request_body(query=query, page_size=constants.TOP_K, timeout_secs=20)

        # new_matching_query
        tobe_request_body['query']['boosting']['positive']['function_score']['query']['bool']['filter'][2]['bool']['must'][0]['multi_match']['fields'].append("content_keywords")
        tobe_request_body['query']['boosting']['positive']['function_score']['query']['bool']['filter'][1]['multi_match'][
            'fields'].append("content_keywords")

        tobe_request_body['query']['boosting']['negative']['bool']['should'].append(content_only_negative)
        """
        if brand_query_res.get("brand_keyword"):
            new_rank_features = [
                {
                    "filter": {
                        "bool": {
                            "minimum_should_match": 1,
                            "should": [
                                {
                                    "multi_match": {
                                        "fields": [
                                            "brand_name",
                                            "processed_brand_name",
                                            "brand_name.standard",
                                            "brand_name.no_syn"
                                        ],
                                        "operator": "or",
                                        "query": brand_query_res.get("brand_keyword"),
                                        "type": "cross_fields"
                                    }
                                }
                            ]
                        }
                    },
                    "weight": 0.02068615
                }
            ]

            tobe_request_body['query']['boosting']['positive']['function_score']['functions'] = tobe_request_body['query']['boosting']['positive']['function_score']['functions'] + new_rank_features
        """
        #print(tobe_request_body)

        tobe_res = ES.get_search_result(
            # request_body=multimatch_to_match.generate(query, top_k=constants.TOP_K),
            # request_body=add_matching_similarity.generate(query, top_k=constants.TOP_K),
            # request_body=proximity.generate(query, top_k=constants.TOP_K),
            # request_body=normalize_bm25.generate(query, top_k=constants.TOP_K),
            # request_body=should_validate2.generate(query, top_k=constants.TOP_K),
            request_body=tobe_request_body,
            explain=True, 
            top_k=constants.TOP_K,
            with_elapsed=True,
        )

        tobe1_res = ES_DEV.get_search_result(
            # request_body=multimatch_to_match.generate(query, top_k=constants.TOP_K),
            # request_body=add_matching_similarity.generate(query, top_k=constants.TOP_K),
            # request_body=proximity.generate(query, top_k=constants.TOP_K),
            # request_body=normalize_bm25.generate(query, top_k=constants.TOP_K),
            # request_body=should_validate2.generate(query, top_k=constants.TOP_K),
            request_body=tobe_request_body,
            explain=True,
            top_k=constants.TOP_K,
            with_elapsed=True,
        )

        tobe_docs = get_docs(tobe_res)
        tobe1_docs = get_docs(tobe1_res)

        # ê²€ìƒ‰ì¿¼ë¦¬ë¬¸
        col1, mid, col2 = st.columns([1, 0.2, 1])
        with col1:
            with st.expander("Request Body"):
                st.json(asis_res["requestBody"])

        with mid:
            with st.expander("Request Body"):
                st.json(tobe1_res["requestBody"])

        with col2:
            with st.expander("Request Body"):
                st.json(tobe_res["requestBody"])

        asis_id2rank = get_id2rank(asis_docs)
        tobe_id2rank = get_id2rank(tobe_docs)
        tobe1_id2rank = get_id2rank(tobe1_docs)

        if option_debug == "Debug":
            debug_cols = st.columns(2)
            # extra_cols[0].info(f"elapsed: {asis_elapsed}")
            # extra_cols[1].info(f"elapsed: {tobe_elapsed}")
            score_list = [doc["_score"] for doc in asis_docs]
            plot = visualize.draw_distribution(
                score_list, 
                x="Rank", 
                y="Score", 
                title="ASIS Score Distribution"
            )
            debug_cols[0].pyplot(plot)
            # debug_cols[0].write(f'ê²€ìƒ‰ê²°ê³¼ìˆ˜: {asis_res["result"]["hits"]["total"]["value"]}')

            score_list = [doc["_score"] for doc in tobe_docs]
            plot = visualize.draw_distribution(
                score_list, 
                x="Rank", 
                y="Score", 
                title="TOBE Score Distribution"
            )
            debug_cols[1].pyplot(plot)
            # debug_cols[1].write(f'ê²€ìƒ‰ê²°ê³¼ìˆ˜: {tobe_res["result"]["hits"]["total"]["value"]}')

        num_cols = 5    # í™€ìˆ˜ë¡œ ë³€ê²½: 5 ë˜ëŠ” 7 ê¶Œì¥
        mid = int((num_cols-1)/2)
        col_size_list = [1]*num_cols
        col_size_list[mid] *= 0.2   # this is border
        cols = st.columns(col_size_list)
        left_cols = cols[:mid]
        mid_cols = cols[mid]
        right_cols = cols[mid+1:]

        for name, docs in [("asis", asis_docs), ("tobe", tobe_docs), ("tobe1", tobe1_docs)]:
            # select columns
            if name == "asis":
                this_cols = left_cols
            elif name == "tobe1":
                this_cols = mid_cols
            else:
                this_cols = right_cols

            if len(docs) == 0:
                col = this_cols[0 % mid]
                col.subheader("ğŸ™ˆ ê²€ìƒ‰ê²°ê³¼ì—†ìŒ!")
                continue

            for rank, doc in enumerate(docs):
                if name=='tobe1':
                    col = this_cols
                else:
                    col = this_cols[rank % mid]

                if rank == constants.SHOW_K:
                    break

                with col:
                    doc_url, _ = ES.get_document(doc["_id"], only_return_url=True)

                    col.markdown((
                        f'{rank+1}.'
                        f'{get_rank_changes(asis_id2rank, tobe_id2rank, doc["_id"], constants.TOP_K)}'
                        f' **`ì ìˆ˜:{doc["_score"]}`**'
                        f' [{doc["_id"]}]({get_service_doc_url("ìŠ¤í† ì–´", doc["_id"])})'
                        f' [`doc`]({doc_url})'
                        # f' `{timediff(doc["created_at"][:10])}`'
                    ))
                    commerce_view.service_view(
                        col=col,
                        rank=rank+1, 
                        doc=doc, 
                        doc_url=doc_url, 
                        use_badges=False, 
                        debug=True if option_debug == "Debug" else False
                    )
